{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Let $x$ be a random variable. Consider the moment generating function\n",
    "$$\n",
    "\\phi_x: \\mathbb{R} \\to \\mathbb{R}, \\quad s \\mapsto \\mathbb{E}[\\exp(sx)].\n",
    "$$\n",
    "\n",
    "\n",
    "**Context:** Moment generating functions offer a practical method for determining the distribution of a sum $x_1 + \\cdots + x_n$ of random variables $x_1, \\ldots, x_n$ (Exercise 1c). \n",
    "\n",
    "Recall that we first introduced Markov's inequality, which provides a loose bound based on the expectation alone. We then used Markov's inequality to derive Chebyshev's inequality, which is likely to give a tighter bound than Markov's inequality, but additionally requires knowledge about the variance.\n",
    "\n",
    "In addition, we used Markov's inequality to derive Chernoff's bound. This bound uses all higher-order moments of a random variable implicitly summarized in a moment generating function. Chernoff's bound in turn can be used to derive Hoeffding's inequality. In the context of these concentration inequalities, we consider moment generating functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**(a)**\n",
    "The exponential distribution with parameter $\\lambda>0$ is\n",
    "$$\n",
    "p_{\\lambda}(x)=\\begin{cases}\n",
    "\\lambda \\exp(-\\lambda x) & x\\geq 0\\\\\n",
    "0 & x<0\n",
    "\\end{cases}.\n",
    "$$\n",
    "Let $\\lambda > s$. Show that\n",
    "$$\n",
    "\\phi_x(s)= \\frac{\\lambda}{\\lambda-s}\n",
    "$$\n",
    "for an exponentially distributed random variable $x$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\phi_z(s)\n",
    "&= \\mathbb{E}[\\exp(sx)] \\\\\n",
    "&= \\int_0^{\\infty} \\exp(sx) p_{\\lambda}(x) dx\\\\\n",
    "&= \\int_0^{\\infty} \\exp(sx) \\lambda\\exp(-\\lambda x) dx\\\\\n",
    "&= \\lambda \\int_0^{\\infty} \\exp((s-\\lambda)x) dx\\\\\n",
    "&= \\frac{\\lambda}{s-\\lambda}\\Big[\\exp((s-\\lambda)x)\\Big]_0^{\\infty}\\\\\n",
    "&= \\frac{\\lambda}{s-\\lambda}(0 - 1)\n",
    "= \\frac{\\lambda}{\\lambda - s}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Note that we used $\\lim_{x\\to\\infty} \\exp((s-\\lambda)x) = 0$ if $\\lambda>s$.\n",
    "\n",
    "**Remark:** The integral diverges for $s\\geq t$. For $s=t$ the integrand is the identity $1$ and for $s > t$ the exponent is positive. Therefore, in both cases, the integral diverges to infinity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**(b)**\n",
    "Show that $\\phi_x(s)$ satisfies the following properties:\n",
    "\n",
    "1. $\\phi_x(0) = 1$\n",
    "2. $\\phi^{(k)}_x(0) = \\mathbb{E}[x^k]$ for any integer $k\\geq 0$\n",
    "\n",
    "where $\\phi^{(k)}_x(s)$ is the $k^{\\text{th}}$ derivative of $\\phi_x$ at $s$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "The first property follows from\n",
    "$$\n",
    "\\phi_x(0) = \\mathbb{E}[\\exp(0x)] = \\mathbb{E}[1] = 1.\n",
    "$$\n",
    "\n",
    "To show the second property, let $\\partial_s^{(k)}$ denote the $k^{\\text{th}}$ derivative with respect to $s$. Then we have\n",
    "\n",
    "$$\n",
    "\\phi_x^{(k)}(s) \n",
    "= \\partial_s^{(k)}\\,\\mathbb{E}[\\exp(sx)] \n",
    "= \\mathbb{E}[\\partial_s^{(k)}\\exp(sx)].\n",
    "$$\n",
    "\n",
    "Observe that\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\partial_{s}^{(1)} \\exp(sx) &= x\\exp(sx)\\\\\n",
    "\\partial_{s}^{(2)} \\exp(sx) &= \\partial_{s}^{(1)}x\\exp(sx) = x^2 \\exp(sx)\\\\\n",
    "&\\vdots\\\\\n",
    "\\partial_{s}^{(k)} \\exp(sx) &= x^k\\exp(sx).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Combining the results, we obtain $\\phi_x^{(k)}(s) = \\mathbb{E}\\left[x^k\\exp(sx)\\right]$. Thus, setting $s = 0$ yields the assertion\n",
    "\n",
    "$$\n",
    "\\phi_x^{(k)}(0) = \\mathbb{E}\\left[x^k\\right].\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**(c)**\n",
    "Consider the independent random variables $x_1, \\ldots, x_n$. Let $z = x_1+\\cdots+x_n$. Show that \n",
    "$$\n",
    "\\phi_z(s) = \\prod_{i=1}^n \\phi_{x_i}(s).\n",
    "$$\n",
    "What is the form of $\\phi_z(s)$ when the random variables $x_i$ are also identically distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Let $z = x + y$ be the sum of two independent random variables $x$ and $y$. Then\n",
    "\n",
    "$$\n",
    "\\phi_z(s) = \\mathbb{E}[\\exp(sz)] = \\mathbb{E}[\\exp(s(x+y))] = \\mathbb{E}[\\exp(sx)\\exp(sy)]\n",
    "$$\n",
    "\n",
    "By independence of $x$ and $y$, we have \n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\exp(sx)\\exp(sy)] = \\mathbb{E}[\\exp(sx)]\\mathbb{E}[\\exp(sy)]\n",
    "= \\phi_x(s) \\phi_y(s).\n",
    "$$\n",
    "\n",
    "This shows $\\phi_z(s) = \\phi_x(s) \\phi_y(s)$. \n",
    "\n",
    "Now let $z = x_1+\\cdots+x_n$. From he previous result for $n = 2$ immediately follows \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\phi_z(s) \n",
    "&= \\mathbb{E}[\\exp(s(x_1+\\cdots+x_n))] \\\\\n",
    "&= \\mathbb{E}[\\exp(sx_1)]\\mathbb{E}[\\exp(sx_2)] \\cdots \\mathbb{E}[\\exp(sx_n)]\\\\\n",
    "&= \\prod_{i=1}^n \\phi_{x_i}(s).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "If the random variables $x_1, \\ldots, x_n$ are i.i.d., we have\n",
    "\n",
    "$$\n",
    "\\prod_i^{n}\\phi_{x_i}(s) = \\prod_i^{n}\\phi_{x_1}(s) = \\left(\\phi_{x_1}(s)\\right)^n.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**(d)** Let $x_1, \\ldots, x_n$ be i.i.d. Bernoulli random variables with parameter $p$. Let $z=x_1+\\cdots+x_n$ be the sum. Use $\\phi_z(s)$ to show that $\\mathbb{E}[z] = np$ and optionally $\\mathbb{V}[z] = np(1-p)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** \n",
    "\n",
    "The moment generating function of $z$ is\n",
    "\n",
    "$$\n",
    "\\phi_z(s) = \\mathbb{E}[\\exp(s(x_1+\\cdots+x_n))]= \\left(\\phi_{x_1}(s)\\right)^n.\n",
    "$$\n",
    "\n",
    "Let $x$ be a Bernoulli random variable with parameter $p$. Then, \n",
    "\n",
    "$$\n",
    "\\phi_{x}(s) = \\mathbb{E}[\\exp(sx)] = p\\exp(1 \\cdot s) + (1-p)\\exp(0 \\cdot s) = p\\exp(s) +(1-p).\n",
    "$$\n",
    "\n",
    "Combining both results gives $\\phi_z(s) = (p\\exp(s) +(1-p))^n$. \n",
    "\n",
    "To derive the expectation and variance, we use property (2) of exercise (1b) and compute the derivatives $\\phi'_z(s)$ and $\\phi''_z(s)$ at $s = 0$. \n",
    "\n",
    "To simplify the computation, we set $g(s) = p\\exp(s) + (1-p)$. The function $g(s)$ has the following properties:\n",
    "\n",
    "\n",
    "1. $g^{(k)}(s) = p\\exp(s)$\n",
    "\n",
    "2. $g^{(k)}(0) = p$ \n",
    "\n",
    "3. $g(0) = 1$\n",
    "\n",
    "for all integers $k>0$. From $\\phi_z(s) = g(s)^n$ follows by the chain rule\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\phi'_z(s) \n",
    "&= n g(s)^{n-1} g'(s) \\\\\n",
    "\\phi''_z(s) \n",
    "&= n(n-1) g(s)^{n-2} g'(s)^2 + n g(s)^{n-1} g''(s)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Setting $s = 0$ and using properties (2) and (3) of $g$ gives\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\phi'_z(0)  &= n g(0)^{n-1} g'(0) = np\\\\\n",
    "\\phi''_z(s) \n",
    "&= n(n-1) g(0)^{n-2} g'(0)^2 + n g(0)^{n-1} g''(0)\\\\\n",
    "&= n(n-1)p^2 + np \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus, the expectation is $\\mathbb{E}[z] = \\phi'_z(0) = np$. For the variance, we obtain\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{V}[z] \n",
    "&= \\mathbb{E}[z^2] - \\mathbb{E}[z]^2\\\\\n",
    "&= \\phi''(0) - \\phi'(0)^2\\\\\n",
    "&= n(n-1)p^2 + np - n^2p^2 \\\\\n",
    "&= np - np^2 = np(1-p).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "This completes the proof."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
